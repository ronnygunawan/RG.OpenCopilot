# Executor Service Implementation Plan

## Overview

This document outlines the complete implementation plan for the container-based executor service that will use MCP (Model Context Protocol) tools to actually modify code, run builds/tests, and implement the plan steps generated by the planner.

## Current State (‚úÖ Completed)

### Infrastructure
- ‚úÖ Docker container management (create, execute, cleanup)
- ‚úÖ Repository cloning inside containers
- ‚úÖ Command execution in isolated containers
- ‚úÖ File read/write API (`ReadFileInContainerAsync`, `WriteFileInContainerAsync`)
- ‚úÖ Automatic project detection (.NET, Node.js, Python)
- ‚úÖ Build and test command execution
- ‚úÖ Commit and push from containers
- ‚úÖ PR comment posting for progress updates
- ‚úÖ Comprehensive test coverage (44 tests)
- ‚úÖ Security scanning (0 vulnerabilities)

### Current Limitations
- ‚ö†Ô∏è Steps are marked as done without actual code modifications
- ‚ö†Ô∏è MCP tools (bash, view, edit, create) not yet integrated with LLM
- ‚ö†Ô∏è No LLM-driven code analysis and generation
- ‚ö†Ô∏è File operations available but not used for actual modifications

## Required Functionalities (üìã To Be Implemented)

### Phase 1: MCP Tool Integration for File Operations

#### 1.1 File Reading and Analysis
**What**: Use MCP tools to read and analyze repository files inside containers

**Why**: Need to understand existing code structure before making changes

**How**:
- Use `docker exec` to run `cat` commands for file reading (already available via `ReadFileInContainerAsync`)
- Parse file content to understand structure (classes, functions, imports, etc.)
- Build a file tree/map of the repository
- Identify relevant files for each plan step

**Implementation**:
```csharp
public class FileAnalyzer
{
    private readonly IContainerManager _containerManager;
    
    public async Task<FileStructure> AnalyzeFileAsync(string containerId, string filePath)
    {
        // Read file content
        var content = await _containerManager.ReadFileInContainerAsync(containerId, filePath);
        
        // Parse based on file extension
        var structure = ParseFile(filePath, content);
        
        return structure;
    }
    
    public async Task<List<string>> ListFilesAsync(string containerId, string pattern)
    {
        // Use docker exec to run find/ls commands
        var result = await _containerManager.ExecuteInContainerAsync(
            containerId, 
            "find", 
            new[] { ".", "-name", pattern }
        );
        
        return ParseFileList(result.Output);
    }
}
```

#### 1.2 File Creation and Modification
**What**: Use MCP tools to create new files and modify existing ones

**Why**: Core functionality for implementing code changes

**How**:
- Use `WriteFileInContainerAsync` (already implemented) for file creation
- For modifications, read existing content, apply changes, write back
- Track all file changes for commit message generation

**Implementation**:
```csharp
public class FileEditor
{
    private readonly IContainerManager _containerManager;
    private readonly List<FileChange> _changes = new();
    
    public async Task CreateFileAsync(string containerId, string filePath, string content)
    {
        await _containerManager.WriteFileInContainerAsync(containerId, filePath, content);
        _changes.Add(new FileChange { Type = ChangeType.Created, Path = filePath });
    }
    
    public async Task ModifyFileAsync(string containerId, string filePath, Func<string, string> transform)
    {
        var content = await _containerManager.ReadFileInContainerAsync(containerId, filePath);
        var newContent = transform(content);
        await _containerManager.WriteFileInContainerAsync(containerId, filePath, newContent);
        _changes.Add(new FileChange { Type = ChangeType.Modified, Path = filePath });
    }
    
    public IReadOnlyList<FileChange> GetChanges() => _changes.AsReadOnly();
}
```

#### 1.3 Directory Operations
**What**: Create directories, move files, organize structure

**Why**: May need to create new directories for new features or reorganize code

**How**:
- Use `docker exec` with `mkdir -p` for directory creation
- Use `mv` command for moving files
- Use `rm -rf` for deletions (with safety checks)

**Implementation**:
```csharp
public async Task CreateDirectoryAsync(string containerId, string dirPath)
{
    await _containerManager.ExecuteInContainerAsync(
        containerId,
        "mkdir",
        new[] { "-p", dirPath }
    );
}

public async Task MoveFileAsync(string containerId, string source, string dest)
{
    await _containerManager.ExecuteInContainerAsync(
        containerId,
        "mv",
        new[] { source, dest }
    );
}
```

### Phase 2: LLM Integration for Code Generation

#### 2.1 Step Analyzer
**What**: Analyze plan steps to determine what code changes are needed

**Why**: Need to understand the intent of each step before generating code

**How**:
- Use LLM (GPT-4 or cheaper model) to analyze step title and details
- Provide repository context (file structure, existing code)
- Generate specific action plan: "Create class X in file Y", "Modify function Z to do W"

**Implementation**:
```csharp
public class StepAnalyzer
{
    private readonly IChatCompletionService _llm;
    
    public async Task<StepActionPlan> AnalyzeStepAsync(
        PlanStep step, 
        RepositoryContext context)
    {
        var prompt = BuildAnalysisPrompt(step, context);
        var response = await _llm.GetChatMessageContentAsync(prompt);
        return ParseActionPlan(response.Content);
    }
    
    private string BuildAnalysisPrompt(PlanStep step, RepositoryContext context)
    {
        return $@"
Analyze this development step and determine what code changes are needed:

Step: {step.Title}
Details: {step.Details}

Repository Context:
- Language: {context.Language}
- Files: {string.Join(", ", context.Files)}
- Test Framework: {context.TestFramework}

Provide a specific action plan with:
1. Which files to create or modify
2. What changes to make to each file
3. Any dependencies or prerequisites
";
    }
}
```

#### 2.2 Code Generator
**What**: Generate actual code based on the action plan

**Why**: Core functionality to implement the requested changes

**How**:
- Use LLM with code-specific prompts
- Provide examples from existing codebase for consistency
- Generate code that matches project style and patterns
- Validate generated code with syntax checking

**Implementation**:
```csharp
public class CodeGenerator
{
    private readonly IChatCompletionService _llm;
    
    public async Task<string> GenerateCodeAsync(
        CodeGenerationRequest request,
        string existingCode = null)
    {
        var prompt = BuildCodePrompt(request, existingCode);
        var response = await _llm.GetChatMessageContentAsync(prompt);
        return ExtractCode(response.Content);
    }
    
    private string BuildCodePrompt(CodeGenerationRequest request, string existingCode)
    {
        return $@"
Generate {request.Language} code for the following requirement:

Task: {request.Description}
File: {request.FilePath}

{(existingCode != null ? $"Existing code:\n```{request.Language}\n{existingCode}\n```" : "")}

Requirements:
- Follow best practices for {request.Language}
- Include appropriate error handling
- Add XML documentation comments
- Match the existing code style

Provide only the code without explanations.
";
    }
}
```

#### 2.3 Test Generator
**What**: Generate unit tests for new or modified code

**Why**: Ensure code quality and catch issues early

**How**:
- Detect test framework (xUnit, NUnit, pytest, Jest, etc.)
- Generate tests that follow existing patterns
- Create test files in appropriate locations
- Run tests to verify they pass

**Implementation**:
```csharp
public class TestGenerator
{
    private readonly IChatCompletionService _llm;
    private readonly IContainerManager _containerManager;
    
    public async Task<string> GenerateTestsAsync(
        string containerId,
        string codeFilePath,
        string codeContent,
        string testFramework)
    {
        // Analyze existing tests for patterns
        var existingTests = await FindExistingTestsAsync(containerId);
        var testPattern = AnalyzeTestPattern(existingTests);
        
        // Generate tests
        var prompt = BuildTestPrompt(codeFilePath, codeContent, testFramework, testPattern);
        var response = await _llm.GetChatMessageContentAsync(prompt);
        
        return ExtractCode(response.Content);
    }
    
    public async Task<bool> RunTestsAsync(string containerId, string testFilePath)
    {
        var result = await _containerManager.ExecuteInContainerAsync(
            containerId,
            "dotnet",
            new[] { "test", testFilePath, "--no-build" }
        );
        
        return result.Success;
    }
}
```

### Phase 3: Iterative Execution with Feedback

#### 3.1 Build Verification
**What**: Run builds after each change and handle errors

**Why**: Catch compilation errors immediately and fix them

**How**:
- Run build command after file modifications
- Parse build errors
- Use LLM to fix errors if they occur
- Retry with corrections

**Implementation**:
```csharp
public class BuildVerifier
{
    private readonly IContainerManager _containerManager;
    private readonly IChatCompletionService _llm;
    
    public async Task<BuildResult> VerifyBuildAsync(string containerId, int maxRetries = 3)
    {
        for (int attempt = 1; attempt <= maxRetries; attempt++)
        {
            var result = await RunBuildAsync(containerId);
            
            if (result.Success)
                return BuildResult.Success();
            
            if (attempt < maxRetries)
            {
                // Use LLM to fix build errors
                var fixes = await GenerateFixesAsync(result.Errors);
                await ApplyFixesAsync(containerId, fixes);
            }
            else
            {
                return BuildResult.Failed(result.Errors);
            }
        }
        
        return BuildResult.Failed("Max retries exceeded");
    }
    
    private async Task<CommandResult> RunBuildAsync(string containerId)
    {
        // Detect build tool and run appropriate command
        var hasDotnet = await FileExistsAsync(containerId, "*.csproj");
        
        if (hasDotnet)
        {
            return await _containerManager.ExecuteInContainerAsync(
                containerId, 
                "dotnet", 
                new[] { "build" }
            );
        }
        
        // Add other build tools (npm, gradle, etc.)
        throw new NotSupportedException("Build tool not detected");
    }
}
```

#### 3.2 Test Execution and Validation
**What**: Run tests and ensure they pass

**Why**: Verify that changes don't break existing functionality

**How**:
- Run test suite after code changes
- Parse test results
- Fix failing tests with LLM assistance
- Report test results in PR comments

**Implementation**:
```csharp
public class TestValidator
{
    private readonly IContainerManager _containerManager;
    private readonly IChatCompletionService _llm;
    
    public async Task<TestResult> RunAndValidateTestsAsync(
        string containerId, 
        int maxRetries = 2)
    {
        for (int attempt = 1; attempt <= maxRetries; attempt++)
        {
            var result = await RunTestsAsync(containerId);
            
            if (result.AllPassed)
                return TestResult.Success(result);
            
            if (attempt < maxRetries)
            {
                // Analyze failures and generate fixes
                var fixes = await AnalyzeTestFailuresAsync(result.Failures);
                await ApplyTestFixesAsync(containerId, fixes);
            }
            else
            {
                return TestResult.Failed(result);
            }
        }
        
        return TestResult.Failed("Max retries exceeded");
    }
}
```

#### 3.3 Code Review Integration
**What**: Run automated code quality checks

**Why**: Maintain code quality standards

**How**:
- Run linters (dotnet format, eslint, black, etc.)
- Check code style compliance
- Run static analysis tools
- Auto-fix issues when possible

**Implementation**:
```csharp
public class CodeQualityChecker
{
    private readonly IContainerManager _containerManager;
    
    public async Task<QualityResult> CheckAndFixAsync(string containerId)
    {
        var issues = new List<QualityIssue>();
        
        // Run linter
        var lintResult = await RunLinterAsync(containerId);
        if (!lintResult.Success)
        {
            // Auto-fix if possible
            await AutoFixLintIssuesAsync(containerId);
            issues.AddRange(ParseLintIssues(lintResult.Output));
        }
        
        // Run static analysis (if available)
        // Check for security issues
        // Verify documentation coverage
        
        return new QualityResult { Issues = issues };
    }
}
```

### Phase 4: Enhanced Step Execution

#### 4.1 Complete Step Executor
**What**: Orchestrate all components to execute a single plan step

**Why**: Bring together all the pieces into a cohesive workflow

**How**:
- Analyze step with LLM
- Generate code changes
- Apply changes to files
- Run build to verify
- Run tests to validate
- Fix any issues
- Track progress

**Implementation**:
```csharp
public class SmartStepExecutor
{
    private readonly StepAnalyzer _analyzer;
    private readonly CodeGenerator _codeGenerator;
    private readonly TestGenerator _testGenerator;
    private readonly FileEditor _fileEditor;
    private readonly BuildVerifier _buildVerifier;
    private readonly TestValidator _testValidator;
    
    public async Task<StepExecutionResult> ExecuteStepAsync(
        string containerId,
        PlanStep step,
        RepositoryContext context,
        CancellationToken cancellationToken)
    {
        try
        {
            // 1. Analyze what needs to be done
            var actionPlan = await _analyzer.AnalyzeStepAsync(step, context);
            
            // 2. Generate and apply code changes
            foreach (var action in actionPlan.Actions)
            {
                if (action.Type == ActionType.CreateFile)
                {
                    var code = await _codeGenerator.GenerateCodeAsync(action.Request);
                    await _fileEditor.CreateFileAsync(containerId, action.FilePath, code);
                }
                else if (action.Type == ActionType.ModifyFile)
                {
                    var existingCode = await ReadFileAsync(containerId, action.FilePath);
                    var newCode = await _codeGenerator.GenerateCodeAsync(action.Request, existingCode);
                    await _fileEditor.ModifyFileAsync(containerId, action.FilePath, _ => newCode);
                }
            }
            
            // 3. Generate tests if needed
            if (actionPlan.RequiresTests)
            {
                var testCode = await _testGenerator.GenerateTestsAsync(
                    containerId, 
                    actionPlan.MainFile, 
                    context.TestFramework
                );
                await _fileEditor.CreateFileAsync(containerId, actionPlan.TestFile, testCode);
            }
            
            // 4. Verify build
            var buildResult = await _buildVerifier.VerifyBuildAsync(containerId);
            if (!buildResult.Success)
            {
                return StepExecutionResult.Failed($"Build failed: {buildResult.Error}");
            }
            
            // 5. Run tests
            var testResult = await _testValidator.RunAndValidateTestsAsync(containerId);
            if (!testResult.AllPassed)
            {
                return StepExecutionResult.Failed($"Tests failed: {testResult.Summary}");
            }
            
            // 6. Return success with details
            return StepExecutionResult.Success(
                changes: _fileEditor.GetChanges(),
                buildOutput: buildResult.Output,
                testResults: testResult
            );
        }
        catch (Exception ex)
        {
            return StepExecutionResult.Failed($"Exception: {ex.Message}");
        }
    }
}
```

#### 4.2 Progress Tracking and Reporting
**What**: Track execution progress and provide detailed updates

**Why**: Keep users informed and enable debugging

**How**:
- Log each action taken
- Capture outputs from builds and tests
- Format progress updates for PR comments
- Include links to changed files

**Implementation**:
```csharp
public class ProgressReporter
{
    private readonly IGitHubService _gitHubService;
    
    public async Task ReportStepProgressAsync(
        AgentTask task,
        PlanStep step,
        StepExecutionResult result,
        int prNumber)
    {
        var comment = FormatProgressComment(step, result);
        
        await _gitHubService.PostPullRequestCommentAsync(
            task.RepositoryOwner,
            task.RepositoryName,
            prNumber,
            comment
        );
    }
    
    private string FormatProgressComment(PlanStep step, StepExecutionResult result)
    {
        var sb = new StringBuilder();
        sb.AppendLine($"## Step: {step.Title}");
        sb.AppendLine();
        
        if (result.Success)
        {
            sb.AppendLine("‚úÖ **Completed successfully**");
            sb.AppendLine();
            sb.AppendLine("### Changes Made:");
            foreach (var change in result.Changes)
            {
                sb.AppendLine($"- {change.Type}: `{change.Path}`");
            }
            sb.AppendLine();
            sb.AppendLine($"### Build: {result.BuildResult.Summary}");
            sb.AppendLine($"### Tests: {result.TestResult.Summary}");
        }
        else
        {
            sb.AppendLine($"‚ùå **Failed**: {result.Error}");
        }
        
        sb.AppendLine();
        sb.AppendLine("---");
        sb.AppendLine("_Automated update by RG.OpenCopilot_");
        
        return sb.ToString();
    }
}
```

### Phase 5: Advanced Features

#### 5.1 Multi-File Refactoring
**What**: Handle changes that span multiple files

**Why**: Some tasks require coordinated changes across files

**How**:
- Identify all affected files
- Plan changes in dependency order
- Apply changes atomically
- Verify entire changeset compiles

#### 5.2 Dependency Management
**What**: Add or update package dependencies

**Why**: New features may require new libraries

**How**:
- Detect package manager (NuGet, npm, pip, etc.)
- Use LLM to determine needed packages
- Run package install commands
- Update dependency files

#### 5.3 Documentation Generation
**What**: Generate or update documentation

**Why**: Keep documentation in sync with code changes

**How**:
- Generate XML docs, JSDoc, docstrings
- Update README files
- Create API documentation
- Update CHANGELOG

## Implementation Timeline

### Sprint 1: Foundation (Week 1-2)
- [ ] Implement FileAnalyzer
- [ ] Implement FileEditor with change tracking
- [ ] Implement directory operations
- [ ] Add comprehensive tests
- [ ] Document MCP tool integration

### Sprint 2: LLM Integration (Week 3-4)
- [ ] Implement StepAnalyzer with LLM
- [ ] Implement CodeGenerator
- [ ] Implement TestGenerator
- [ ] Add prompt engineering best practices
- [ ] Test with various code scenarios

### Sprint 3: Verification & Iteration (Week 5-6)
- [ ] Implement BuildVerifier with retry logic
- [ ] Implement TestValidator with fix generation
- [ ] Implement CodeQualityChecker
- [ ] Add error recovery mechanisms
- [ ] End-to-end testing

### Sprint 4: Complete Integration (Week 7-8)
- [ ] Implement SmartStepExecutor
- [ ] Implement ProgressReporter
- [ ] Integrate all components
- [ ] Performance optimization
- [ ] Production readiness

### Sprint 5: Advanced Features (Week 9-10)
- [ ] Multi-file refactoring support
- [ ] Dependency management
- [ ] Documentation generation
- [ ] Enhanced error handling
- [ ] Final polish and release

## Success Metrics

1. **Code Quality**: Generated code compiles without errors 95%+ of the time
2. **Test Coverage**: Generated tests have 80%+ coverage of new code
3. **Build Success**: Builds succeed on first try 90%+ of the time
4. **Test Pass Rate**: Tests pass on first try 85%+ of the time
5. **User Satisfaction**: Issues resolved correctly 80%+ of the time

## Risks and Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| LLM generates incorrect code | High | Implement build/test verification with retries |
| Context window limitations | Medium | Implement smart context selection and chunking |
| API rate limits | Medium | Implement caching and request batching |
| Container resource usage | Low | Set resource limits, implement cleanup |
| Security vulnerabilities in generated code | High | Run security scanners, implement review process |

## Dependencies

1. **LLM Provider**: OpenAI API or Azure OpenAI
2. **Docker**: For container management
3. **Git**: For version control
4. **Build Tools**: dotnet, npm, pip, etc.
5. **Test Frameworks**: xUnit, Jest, pytest, etc.

## Configuration Requirements

```json
{
  "Executor": {
    "LLM": {
      "Provider": "OpenAI",
      "Model": "gpt-4o",
      "MaxTokens": 4096,
      "Temperature": 0.2
    },
    "Container": {
      "BaseImage": "mcr.microsoft.com/dotnet/sdk:10.0",
      "ResourceLimits": {
        "CpuCount": 2,
        "MemoryMb": 4096
      }
    },
    "Execution": {
      "MaxRetries": 3,
      "TimeoutMinutes": 30,
      "EnableParallelExecution": false
    }
  }
}
```

## Open Questions

1. Should we support custom LLM providers beyond OpenAI?
2. How to handle very large files (>10k lines)?
3. Should we implement parallel step execution?
4. What's the strategy for handling breaking changes?
5. How to ensure generated code follows company-specific guidelines?

## Next Steps

1. Review and approve this implementation plan
2. Set up LLM provider credentials
3. Create feature branches for each sprint
4. Begin Sprint 1 implementation
5. Schedule regular reviews and demos
